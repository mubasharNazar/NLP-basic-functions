{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atlantic-spider",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hazardous-process",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.56.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "confidential-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Orange is a sour fruit that is round in shape and is orange colored.', 'Orange is sour and sweet.', 'Orange is a vitamin C rich food as it is one of the primary sources of vitamin C. Eating an orange daily helps overcome the deficiency of Vitamin C in the human body.']\n",
      "['Orange', 'is', 'a', 'sour', 'fruit', 'that', 'is', 'round', 'in', 'shape', 'and', 'is', 'orange', 'colored', '.', 'Orange', 'is', 'sour', 'and', 'sweet', '.', 'Orange', 'is', 'a', 'vitamin', 'C', 'rich', 'food', 'as', 'it', 'is', 'one', 'of', 'the', 'primary', 'sources', 'of', 'vitamin', 'C.', 'Eating', 'an', 'orange', 'daily', 'helps', 'overcome', 'the', 'deficiency', 'of', 'Vitamin', 'C', 'in', 'the', 'human', 'body', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "EXAMPLE_TEXT = \" Orange is a sour fruit that is round in shape and is orange colored. Orange is sour and sweet. Orange is a vitamin C rich food as it is one of the primary sources of vitamin C. Eating an orange daily helps overcome the deficiency of Vitamin C in the human body. \"\n",
    "\n",
    "tokened_sent = sent_tokenize(EXAMPLE_TEXT)\n",
    "tokened_word = word_tokenize(EXAMPLE_TEXT)\n",
    "print(tokened_sent)\n",
    "print(tokened_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "incomplete-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instagram\n",
      "instagramm\n",
      "instagram\n"
     ]
    }
   ],
   "source": [
    "#STEMMING\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"instagram\",\"instagrammer\",\"instagraming\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "improving-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase\n"
     ]
    }
   ],
   "source": [
    "#LEMMATIZATION\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('increases'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "drawn-advice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Orange', 'sour', 'fruit', 'round', 'shape', 'orange', 'colored', '.', 'Orange', 'sour', 'sweet', '.', 'Orange', 'vitamin', 'C', 'rich', 'food', 'one', 'primary', 'sources', 'vitamin', 'C.', 'Eating', 'orange', 'daily', 'helps', 'overcome', 'deficiency', 'Vitamin', 'C', 'human', 'body', '.']\n"
     ]
    }
   ],
   "source": [
    "#FILTERING ALL THE STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "example_sent = example_sent = \" Orange is a sour fruit that is round in shape and is orange colored. Orange is sour and sweet. Orange is a vitamin C rich food as it is one of the primary sources of vitamin C. Eating an orange daily helps overcome the deficiency of Vitamin C in the human body. \" \n",
    "#STOP WORDS ARE PARTICULAR TO RESPECTIVE LANGUAGES(english, spanish, french Et cetera)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "filtered_sentence = [w for w in word_tokens if w not in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "naked-registrar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:1\n",
      "n:29\n",
      " :55\n",
      "a:22\n",
      "v:5\n",
      "l:12\n",
      "e:39\n",
      "y:6\n",
      "i:19\n",
      "d:17\n",
      "s:14\n",
      "o:19\n",
      "w:4\n",
      "r:15\n",
      "f:6\n",
      "u:8\n",
      "t:18\n",
      ".:7\n",
      "D:1\n",
      "b:4\n",
      "g:5\n",
      "h:7\n",
      "m:6\n",
      "k:3\n",
      "p:5\n",
      "c:8\n",
      "H:1\n",
      "W:1\n",
      "R:1\n",
      "S:1\n",
      "x:1\n",
      "U:1\n"
     ]
    }
   ],
   "source": [
    "#COUNTING THE FREQUENCY OF THE WORDS USED\n",
    "import nltk\n",
    "EXAMPLE_TEXT = \"An an valley indeed so no wonder future nature vanity. Debating all she mistaken indulged believed provided declared. He many kept on draw lain song as same. Whether at dearest certain spirits is entered in to. Rich fine bred real use too many good. She compliment unaffected expression favourable any. Unknown chiefly showing to conduct no.\"\n",
    "frequency = nltk.FreqDist(EXAMPLE_TEXT) \n",
    "for key,val in frequency.items(): \n",
    "    print (str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "moving-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms ['rich_people.n.01', 'rich.a.01', 'rich.a.02', 'rich.s.03', 'fat.s.05', 'deep.s.07', 'rich.s.06', 'rich.a.07', 'rich.a.08', 'rich.s.09', 'full-bodied.s.01', 'rich.s.11', 'ample.s.02']\n",
      "['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
     ]
    }
   ],
   "source": [
    "#synonyms and antonyms\n",
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "for syns in wordnet.synsets('rich'):\n",
    "    synonyms.append(syns.name())\n",
    "print (\"synonyms\", synonyms)\n",
    "#FINDING ANTONYMS FROM WORDNETS\n",
    "from nltk.corpus import wordnet\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "traditional-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mubashar.nazar@innovativesolutions.com', 'alpha.gamma@facebook.com']\n"
     ]
    }
   ],
   "source": [
    "#Regular expression\n",
    "import re\n",
    "text = \"Please contact us at mubashar.nazar@innovativesolutions.com for further information.\"+\\\n",
    "        \" You can also give feedback at alpha.gamma@facebook.com\"\n",
    "\n",
    "\n",
    "emails = re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+\", text)\n",
    "print (emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-prison",
   "metadata": {},
   "source": [
    "# Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rotary-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.8/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.8/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.56.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "northern-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "original-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Netflix is a great platform to watch moves\")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('Netflix is a gret platform to watch movies')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-stomach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "attended-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "('Pakistan is a wonderful country','pos'),\n",
    "('food is great','pos'),\n",
    "('Last night was very horrible','neg'),\n",
    "('Tea is funtastic','pos')\n",
    "]\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "naughty-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "organized-ground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print (classifier.accuracy(testing))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
